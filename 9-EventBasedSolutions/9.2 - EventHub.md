# [Azure Event Hubs](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/) <!-- omit in toc -->

## Table of contents <!-- omit in toc -->

- [Introduction](#introduction)
  - [Features](#features)
  - [Concepts](#concepts)
- [Event Hubs Capture](#event-hubs-capture)
  - [Capture windowing](#capture-windowing)
  - [Throughput units](#throughput-units)
- [Processing](#processing)
  - [Designing processing solution](#designing-processing-solution)
  - [Event processor client](#event-processor-client)
  - [Partition ownership tracking](#partition-ownership-tracking)
  - [Checkpointing](#checkpointing)
  - [Receiving messages](#receiving-messages)
  - [Thread safety](#thread-safety)
- [Access control](#access-control)
  - [Azure Active Directory](#azure-active-directory)
  - [Shared access signatures](#shared-access-signatures)
    - [Event Hubs publishers](#event-hubs-publishers)
    - [Event Hubs consumers](#event-hubs-consumers)
- [Performing operations in .NET](#performing-operations-in-net)
  - [Publishing](#publishing)
  - [Reading](#reading)
  - [Processing](#processing-1)

## [Introduction](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/2-event-hubs-overview)

> Azure Event Hubs is an **event ingestor**, it provides a **streaming platform** with time retention buffer for events.

### Features

- **Fully managed PaaS**
  - Little configuration or management
- **Real-time & batch processing**
  - Partitioned consumer model
  - Concurrent stream processing
  - Control over processing speed
- **Capture event data**
  - Near-real time capturing in Blob storage or Data Lake Storage
- **Scaling**
- **Rich ecosystem**
  - Event Hubs for Apache Kafka without clusters

### Concepts

- **Event Hubs client**
  - Interface for developers
  - Different clients for specific uses (publishing/consuming)
- **Event Hubs producer**
  - Client that serves as data source
- **Event Hubs consumer**
  - Client that reads & processes data
  - Often high-scale platform infrastructure parts
  - Can be connected to analytics services like Azure Stream Analytics or Apache Spark
- **Partition**
  - Ordered sequence of events
  - Data organization for parallelism
    - Each consumer reads subset/partition of message stream
  - Number of partitions is fixed at creation
- **Consumer group**
  - View of entire Event Hubs
  - Consuming applications have separate view of event stream
- **Event receivers**
  - Entities that read event data
  - Event Hubs consumers connect via AMQP 1.0
  - Kafka consumers connect via Kafka protocol 1.0 and up
- **Throughput/processing units**
  - Prepurchased units of capacity
  - Throughput = standard tier
  - Processing = premium tier

![Event Hubs architecture](https://learn.microsoft.com/en-us/training/wwl-azure/azure-event-hubs/media/event-hubs-stream-processing.png)

## [Event Hubs Capture](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/3-event-hubs-capture)

> Event Hubs is **time-retention durable**, with a configurable retention time. Event Hubs Capture enables you to **store captured data in a storage account** like Blob storage or Data Lake Store.

Captured data is written in **Apache Avro format**.

### Capture windowing

> You control capturing by setting up a **window**: a minimum size and time configuration. Each **partition captures independently** and writes completed block blobs.

Storage naming convention:

```
{Namespace}/{EventHub}/{PartitionId}/{Year}/{Month}/{Day}/{Hour}/{Minute}/{Second}
```

### Throughput units

> A single throughput unit allows
>
> - 1MB/sec or 1000 events/sec **ingress**
> - Double that amount **egress**
>
> Standard tier hubs can be configured with 1-20 units, more can be purchased. Usage beyond capability is throttled.

> Event Hubs Capture copies directly from interal storage, so throughput units **egress quotas are bypassed**.

## [Processing](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/4-event-processing)

### Designing processing solution

- **Scaling**
  - Create multiple consumers
  - Each consumer reads a few partitions
- **Load balancing**
  - Increase/decrease consumers dynamically
  - Divide number of partitions across consumers accordinly
- **Seamless resume on failures**
  - Other consumers pick up partitions of failing consumers
  - Checkpoint/offset should be at/before point of failure
- **Consuming events**
  - Handle events

### Event processor client

> Event Hubs SDK provides `EventProcessorClient` to handle the above requirements. Multiple clients can work cooperatively within the context of a **consumer group**. They **automatically manage distribution and balancing**.

### Partition ownership tracking

> Event processors each have a unique identifier that they use to claim partitions. This happens in a **checkpoint store**. This store is used to keep its own processing state and to balance the load among other active instances.

### Checkpointing

> Event processors **marks the position of the last successfully processed event** within a partition. Other instances can resume processing from that point.

### Receiving messages

> Processing messages should happen **fast**, each processor should do as little processing as possible. Retry logic is not built-in.

### Thread safety

> Event processing within a partition is done **sequentially**. Different partitions can be processed **concurrently**, shared state across partitions has to be **synchronized**.

## [Access control](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/5-event-hubs-authentication-authorization)

> Event Hubs supports **Azure AD** & **SAS** to handle authentication & authorization.

### Azure Active Directory

Built-in roles for Azure AD:

- **Azure Event Hubs Data Owner**
- **Azure Event Hubs Data Sender**
- **Azure Event Hubs Data Receiver**

> Access can be authorized using **managed identities** or **Microsoft Identity Platform**.

### Shared access signatures

#### Event Hubs publishers

> Event publishers are **virtual endpoints** used to send messages to event hubs. Typically an event hub has **one publisher per `EventHubProducerClient`**. Event Hubs clients are assigned **unique tokens**, that can only send to one publisher. These tokens are **assigned with a SAS key**, which the clients are not aware of.

#### Event Hubs consumers

> **`EventHubConsumerClient/EventProcessorClient`** needs to have the **manage** or **listen** privileges assigned to its namespace or instance/topic.

## [Performing operations in .NET](https://learn.microsoft.com/en-us/training/modules/azure-event-hubs/6-event-hubs-programming-guide)

### Publishing

```dotnet
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

await using (var producer = new EventHubProducerClient(connectionString, eventHubName))
{
    using EventDataBatch eventBatch = await producer.CreateBatchAsync();
    eventBatch.TryAdd(new EventData(new BinaryData("First")));
    eventBatch.TryAdd(new EventData(new BinaryData("Second")));

    await producer.SendAsync(eventBatch);
}
```

### Reading

```dotnet
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsAsync(cancellationSource.Token))
    {
        // At this point, the loop will wait for events to be available in the Event Hub.  When an event
        // is available, the loop will iterate with the event that was received.  Because we did not
        // specify a maximum wait time, the loop will wait forever unless cancellation is requested using
        // the cancellation token.
    }
}
```

```dotnet
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    EventPosition startingPosition = EventPosition.Earliest;
    string partitionId = (await consumer.GetPartitionIdsAsync()).First();

    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsFromPartitionAsync(partitionId, startingPosition, cancellationSource.Token))
    {
        // At this point, the loop will wait for events to be available in the partition.  When an event
        // is available, the loop will iterate with the event that was received.  Because we did not
        // specify a maximum wait time, the loop will wait forever unless cancellation is requested using
        // the cancellation token.
    }
}
```

### Processing

```dotnet
var cancellationSource = new CancellationTokenSource();
cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

var storageConnectionString = "<< CONNECTION STRING FOR THE STORAGE ACCOUNT >>";
var blobContainerName = "<< NAME OF THE BLOB CONTAINER >>"; // needed for state persisting

var eventHubsConnectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";
var consumerGroup = "<< NAME OF THE EVENT HUB CONSUMER GROUP >>";

Task processEventHandler(ProcessEventArgs eventArgs) => Task.CompletedTask;
Task processErrorHandler(ProcessErrorEventArgs eventArgs) => Task.CompletedTask;

var storageClient = new BlobContainerClient(storageConnectionString, blobContainerName);
var processor = new EventProcessorClient(storageClient, consumerGroup, eventHubsConnectionString, eventHubName);

processor.ProcessEventAsync += processEventHandler;
processor.ProcessErrorAsync += processErrorHandler;

await processor.StartProcessingAsync();

try
{
    // The processor performs its work in the background; block until cancellation
    // to allow processing to take place.

    await Task.Delay(Timeout.Infinite, cancellationSource.Token);
}
catch (TaskCanceledException)
{
    // This is expected when the delay is canceled.
}

try
{
    await processor.StopProcessingAsync();
}
finally
{
    // To prevent leaks, the handlers should be removed when processing is complete.

    processor.ProcessEventAsync -= processEventHandler;
    processor.ProcessErrorAsync -= processErrorHandler;
}
```
